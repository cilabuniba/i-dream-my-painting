seed: 42
model:
  pretrained_model_name_or_path: models/stable-diffusion-2-inpainting
  revision: null
  variant: null
  lora_config_partial:
    _partial_: true
    _target_: peft.LoraConfig
    r: 16
    lora_alpha: 16
    lora_dropout: 5.e-2
    init_lora_weights: gaussian
datasets:
  train_partial:
    _partial_: true
    _target_: inpainting.data.datasets.InpaintingDataset
    data_dir: data/mm_inp_dataset
    max_concepts: 5
    generator: null
    shuffle_concepts: true
    masked_area_threshold: 0.65
    resolution: ${resolution}
    freestyle: ${freestyle}
    drop_caption_probability: 0.1
    split: train
  val_partial:
    _partial_: true
    _target_: inpainting.data.datasets.InpaintingDataset
    data_dir: ${datasets.train_partial.data_dir}
    max_concepts: ${datasets.train_partial.max_concepts}
    generator:
      _target_: torch.Generator
    shuffle_concepts: ${datasets.train_partial.shuffle_concepts}
    masked_area_threshold: ${datasets.train_partial.masked_area_threshold}
    resolution: ${resolution}
    freestyle: ${freestyle}
    drop_caption_probability: 0.0
    split: val
dataloaders:
  train_partial:
    _partial_: true
    _target_: torch.utils.data.DataLoader
    batch_size: ${batch_size}
    shuffle: true
    num_workers: 8
  val_partial:
    _partial_: true
    _target_: torch.utils.data.DataLoader
    batch_size: ${batch_size}
    shuffle: false
    num_workers: 8
noise_scheduler:
  _target_: diffusers.DDPMScheduler.from_pretrained
  pretrained_model_name_or_path: ${model.pretrained_model_name_or_path}
  subfolder: scheduler
tokenizer:
  _target_: transformers.CLIPTokenizer.from_pretrained
  pretrained_model_name_or_path: ${model.pretrained_model_name_or_path}
  subfolder: tokenizer
  revision: ${model.revision}
text_encoder:
  _target_: transformers.CLIPTextModel.from_pretrained
  pretrained_model_name_or_path: ${model.pretrained_model_name_or_path}
  subfolder: text_encoder
  revision: ${model.revision}
vae:
  _target_: diffusers.AutoencoderKL.from_pretrained
  pretrained_model_name_or_path: ${model.pretrained_model_name_or_path}
  subfolder: vae
  revision: ${model.revision}
  variant: ${model.variant}
unet:
  _target_: inpainting.models.text_to_image.unets.unet_2d_condition.UNet2DConditionModel.from_pretrained
  pretrained_model_name_or_path: ${model.pretrained_model_name_or_path}
  subfolder: unet
  revision: ${model.revision}
  variant: ${model.variant}
optimizer_partial:
  _partial_: true
  _target_: torch.optim.AdamW # or bitsandbytes.optim.AdamW8Bit
  betas: [0.9, 0.999]
  weight_decay: 0.01
  eps: 1.e-8
scheduler:
  name: constant_with_warmup
  warmup_ratio: 0.01
accelerator:
  _target_: accelerate.Accelerator
  gradient_accumulation_steps: 1
  mixed_precision: fp16
  log_with: wandb
  project_config:
    _target_: accelerate.utils.ProjectConfiguration
    project_dir: models/sd/rca
    logging_dir: ${accelerator.project_config.project_dir}/logs
allow_tf32: false
batch_size: 32
checkpointing_steps: null
do_early_stopping: true
enable_xformers_memory_efficient_attention: false
freestyle: true
gradient_checkpointing: false
learning_rate: 1.e-4
max_grad_norm: 1.0
max_train_samples: null
max_train_steps: null
noise_offset: 0
num_train_epochs: 2
num_validation_images: 5000
prediction_type: null
resolution: 512
resume_from_checkpoint: null
scale_lr: false
snr_gamma: null
validation_epochs: 1
init_trackers_kwargs:
  group: TextToImage
  tags: [lora, rca, train]